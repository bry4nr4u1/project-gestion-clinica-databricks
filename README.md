# ğŸ¥ Project GestiÃ³n ClÃ­nica Databricks

Repositorio de ETL para la gestiÃ³n de datos clÃ­nicos en **Databricks**. Este proyecto implementa un pipeline de datos completo usando la arquitectura **Medallion** (Bronze â†’ Silver â†’ Gold) para la ingesta, transformaciÃ³n y anÃ¡lisis de informaciÃ³n clÃ­nica.

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#descripciÃ³n-general)
- [Objetivos del Proyecto](#objetivos-del-proyecto)
- [Arquitectura](#arquitectura)
- [Fuentes de Datos](#fuentes-de-datos)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Capas de Datos](#capas-de-datos)
- [Flujo del ETL](#flujo-del-etl)
- [Requisitos Previos](#requisitos-previos)
- [GuÃ­a de EjecuciÃ³n](#guÃ­a-de-ejecuciÃ³n)
- [Workflow Automatizado (CI/CD)](#-workflow-automatizado-cicd)
- [DescripciÃ³n de Tablas](#descripciÃ³n-de-tablas)
- [Notas TÃ©cnicas](#notas-tÃ©cnicas)
- [Contacto](#contacto)

---

## ğŸ“ DescripciÃ³n General

Este proyecto implementa un sistema completo de extracciÃ³n, transformaciÃ³n y carga (**ETL**) de datos clÃ­nicos en **Databricks**. Utiliza la arquitectura **Medallion** para organizar los datos en diferentes capas de calidad y complejidad, permitiendo anÃ¡lisis avanzados sobre informaciÃ³n de pacientes, mÃ©dicos, medicamentos, cirugÃ­as y consultas mÃ©dicas.

El proyecto estÃ¡ diseÃ±ado para:
- Ingerir datos desde mÃºltiples fuentes (Data Lake, CosmosDB)
- Transformar y limpiar datos en formato tabular
- Crear vistas analÃ­ticas optimizadas para reportes y anÃ¡lisis

---

## ğŸ¯ Objetivos del Proyecto

1. **Automatizar la ingesta** de datos clÃ­nicos desde fuentes heterogÃ©neas
2. **Normalizar y limpiar** datos para asegurar calidad
3. **Crear una estructural medallion** clara para gobernanza de datos
4. **Proporcionar vistas analÃ­ticas** (capa Gold) para reportes y BI
5. **Implementar trazabilidad** de datos mediante timestamps y auditorÃ­a

---

## ğŸ—ï¸ Arquitectura

![Arquitectura Medallion - GestiÃ³n ClÃ­nica](assets/diagrama_proyecto_etl_clinica_final.png)

---

## ğŸ“Š Fuentes de Datos

El proyecto integra datos de las siguientes fuentes:

### 1. **Data Lake (Azure Blob Storage)**
- **UbicaciÃ³n**: `dtlkbrscceu2d01` container `raw`
- **Formato**: CSV
- **Archivos**:
  - `paciente.csv` - InformaciÃ³n demogrÃ¡fica de pacientes
  - `medico.csv` - Datos de mÃ©dicos y especialidades
  - `medicamento.csv` - CatÃ¡logo de medicamentos
  - `cirugia.csv` - Procedimientos quirÃºrgicos disponibles
  - `consultas_medicas.csv` - Registros de consultas

### 2. **CosmosDB**
- **UbicaciÃ³n**: `cosmosdb/` en datasets
- **Formato**: JSON
- **Archivo**:
  - `historial_pacientes.json` - Historial mÃ©dico completo de pacientes

### 3. **Metastore Databricks**
- **Storage Account**: `adlsbrscceu2d01`
- **Container**: `unit-catalog-clinica`

---

## ğŸ“‚ Estructura del Proyecto

```
project-gestion-clinica-databricks/
â”‚
â”œâ”€â”€ README.md                          # Este archivo
â”‚
â”œâ”€â”€ .github/                           # ConfiguraciÃ³n de CI/CD
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy-notebook.yml        # Workflow de despliegue automÃ¡tico
â”‚
â”œâ”€â”€ assets/                            # Recursos multimedia
â”‚   â”œâ”€â”€ diagrama_proyecto_etl_clinica_final.png
â”‚   â””â”€â”€ ejecucion_wf_carga_datos_clinica.jpg
â”‚
â”œâ”€â”€ datasets/                          # Datos de entrada
â”‚   â”œâ”€â”€ cosmosdb/
â”‚   â”‚   â””â”€â”€ historial_pacientes.json   # Historial en formato JSON
â”‚   â””â”€â”€ datalake/
â”‚       â”œâ”€â”€ paciente.csv
â”‚       â”œâ”€â”€ medico.csv
â”‚       â”œâ”€â”€ medicamento.csv
â”‚       â”œâ”€â”€ cirugia.csv
â”‚       â””â”€â”€ consultas_medicas.csv
â”‚
â”œâ”€â”€ preparacion-ambiente/              # ConfiguraciÃ³n inicial
â”‚   â””â”€â”€ preparacion-ambiente.sql       # Script de creaciÃ³n de catÃ¡logo y tablas
â”‚
â”œâ”€â”€ proceso/                           # Scripts del ETL
â”‚   â”œâ”€â”€ ğŸ“¥ EXTRACCIÃ“N (IngestiÃ³n)
â”‚   â”‚   â”œâ”€â”€ extraer-data-paciente.py
â”‚   â”‚   â”œâ”€â”€ extraer-data-medico.py
â”‚   â”‚   â”œâ”€â”€ extraer-data-medicamento.py
â”‚   â”‚   â”œâ”€â”€ extraer-data-cirugia.py
â”‚   â”‚   â”œâ”€â”€ extraer-data-consultas-medicas.py
â”‚   â”‚   â””â”€â”€ extraer-data-historial-pacientes.py
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”„ TRANSFORMACIÃ“N
â”‚   â”‚   â”œâ”€â”€ transformar-data-clinica.py # Transformaciones Bronze â†’ Silver
â”‚   â”‚   â””â”€â”€ Preparacion_Ambiente.sql    # Setup de ambiente
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“¤ CARGA
â”‚       â””â”€â”€ cargar-data-clinica.py     # Carga a capa Silver y Gold
â”‚
â””â”€â”€ reversion/                         # Scripts de revertir cambios
    â””â”€â”€ eliminar-medallion.sql         # Elimina estructura completa
```

---

## ğŸ”„ Capas de Datos

### **CAPA BRONZE** (Raw - Ingesta)

Replica exacta de los datos de las fuentes sin transformaciÃ³n.

| Tabla | Fuente | DescripciÃ³n |
|-------|--------|-------------|
| `catalogo_clinica.bronze.paciente` | paciente.csv | InformaciÃ³n demogrÃ¡fica de pacientes |
| `catalogo_clinica.bronze.medico` | medico.csv | Datos de profesionales mÃ©dicos |
| `catalogo_clinica.bronze.medicamento` | medicamento.csv | CatÃ¡logo de medicamentos |
| `catalogo_clinica.bronze.cirugia` | cirugia.csv | Procedimientos quirÃºrgicos |
| `catalogo_clinica.bronze.consultas_medicas` | consultas_medicas.csv | Registros de consultas |
| `catalogo_clinica.bronze.historial_pacientes` | historial_pacientes.json | Historial mÃ©dico de pacientes |

**CaracterÃ­sticas**:
- Formato Delta Lake
- Sin transformaciÃ³n de datos
- Incluye timestamps de carga

---

### **CAPA SILVER** (Cleaned - TransformaciÃ³n)

Datos normalizados, validados y sin duplicados.

| Tabla | Origen | DescripciÃ³n |
|-------|--------|-------------|
| `catalogo_clinica.silver.paciente` | bronze.paciente | Pacientes normalizados |
| `catalogo_clinica.silver.medico` | bronze.medico | MÃ©dicos normalizados |
| `catalogo_clinica.silver.medicamento` | bronze.medicamento | Medicamentos normalizados |
| `catalogo_clinica.silver.cirugia` | bronze.cirugia | CirugÃ­as normalizadas |
| `catalogo_clinica.silver.consultas_medicas` | bronze.consultas_medicas | Consultas normalizadas |
| `catalogo_clinica.silver.historial_pacientes_medicamentos` | bronze.historial_pacientes | Historial de medicamentos por paciente |
| `catalogo_clinica.silver.historial_pacientes_cirugias` | bronze.historial_pacientes | Historial de cirugÃ­as por paciente |

**Transformaciones aplicadas**:
- âœ… Limpieza de datos nulos y duplicados
- âœ… NormalizaciÃ³n de formato de strings (trim, case)
- âœ… ValidaciÃ³n de tipos de datos
- âœ… DesnormalizaciÃ³n de arrays JSON
- âœ… AdiciÃ³n de timestamps de procesamiento

---

### **CAPA GOLD** (Curated - AnÃ¡lisis)

Tablas optimizadas para reportes, dashboards y anÃ¡lisis.

| Tabla | DescripciÃ³n | Uso |
|-------|-------------|-----|
| `catalogo_clinica.gold.paciente_perfil_clinico` | Perfil consolidado de pacientes con historial clÃ­nico | BI / Dashboards |
| `catalogo_clinica.gold.consulta_por_medico` | AnÃ¡lisis de consultas por mÃ©dico y especialidad | Reportes mÃ©dicos |
| `catalogo_clinica.gold.ingresos_por_especialidad` | Ingresos agregados por especialidad mÃ©dica | AnÃ¡lisis financiero |
| `catalogo_clinica.gold.medicamentos_consumo` | Consumo y disponibilidad de medicamentos | Inventario |

**CaracterÃ­sticas**:
- Datos desnormalizados para acceso rÃ¡pido
- Agregaciones y KPIs calculados
- Optimizados para consultas BI
- Ãndices y particiÃ³n segÃºn necesidad

---

## ğŸ”€ Flujo del ETL

```
PASO 1: PREPARACIÃ“N DEL AMBIENTE (1 vez)
   â””â”€â–º Run: preparacion-ambiente/preparacion-ambiente.sql
       âœ“ Crea catÃ¡logo "catalogo_clinica"
       âœ“ Crea esquemas: bronze, silver, gold
       âœ“ Crea tablas vacÃ­as en capa bronze
       âœ“ Configura ubicaciones externas

PASO 2: EXTRACCIÃ“N - BRONZE (Ingesta Raw)
   â”œâ”€â–º Run: proceso/extraer-data-paciente.py
   â”œâ”€â–º Run: proceso/extraer-data-medico.py
   â”œâ”€â–º Run: proceso/extraer-data-medicamento.py
   â”œâ”€â–º Run: proceso/extraer-data-cirugia.py
   â”œâ”€â–º Run: proceso/extraer-data-consultas-medicas.py
   â””â”€â–º Run: proceso/extraer-data-historial-pacientes.py
       âœ“ Lee archivos desde Data Lake y CosmosDB
       âœ“ Carga datos en tablas bronze.* sin transformaciÃ³n
       âœ“ Registra timestamp de carga

PASO 3: TRANSFORMACIÃ“N - SILVER (Limpieza)
   â””â”€â–º Run: proceso/transformar-data-clinica.py
       âœ“ Lee datos de tablas bronze.*
       âœ“ Limpia, normaliza y valida
       âœ“ Carga en tablas silver.*
       âœ“ Desnormaliza arrays JSON

PASO 4: CARGA - GOLD (AgregaciÃ³n AnalÃ­tica)
   â””â”€â–º Run: proceso/cargar-data-clinica.py
       âœ“ Lee datos de tablas silver.*
       âœ“ Crea agregaciones y KPIs
       âœ“ Carga en tablas gold.*
       âœ“ Genera vistas analÃ­ticas

RESULTADO:
   âœ… Datos BI-Ready en capa Gold
   âœ… Trazabilidad completa
   âœ… Calidad garantizada
```

---

## ğŸ“‹ Requisitos Previos

### Infraestructura
- âœ… Workspace de **Databricks** activo
- âœ… Acceso a **Azure Data Lake Storage** (ADLS)
- âœ… Acceso a **CosmosDB** (si aplica)
- âœ… **SQL Warehouse** o **All-Purpose Cluster** en Databricks
- âœ… Permisos de lectura/escritura en storage

### ConfiguraciÃ³n
- ğŸ“‹ **CatÃ¡logo**: `catalogo_clinica`
- ğŸ“‹ **Esquemas**: `bronze`, `silver`, `gold`
- ğŸ“‹ **Storage**: Configurar credenciales en Databricks

### Datos
- ğŸ“ Archivos CSV en Data Lake
- ğŸ“„ JSON de historial en CosmosDB

---

## ğŸš€ GuÃ­a de EjecuciÃ³n

### OpciÃ³n 1: EjecuciÃ³n Manual en Databricks

#### 1ï¸âƒ£ **Preparar el Ambiente (Ejecutar 1 vez)**
```sql
-- Abrir: preparacion-ambiente/preparacion-ambiente.sql
-- Click "Run All"
-- Esperar a que se completen todas las celdas
```

#### 2ï¸âƒ£ **Ejecutar ExtracciÃ³n (Bronze)**
```python
# En secuencia:
# 1. Run: extraer-data-paciente.py
# 2. Run: extraer-data-medico.py
# 3. Run: extraer-data-medicamento.py
# 4. Run: extraer-data-cirugia.py
# 5. Run: extraer-data-consultas-medicas.py
# 6. Run: extraer-data-historial-pacientes.py

# Cada notebook debe completarse antes de ejecutar el siguiente
```

#### 3ï¸âƒ£ **Ejecutar TransformaciÃ³n (Silver)**
```python
# Run: transformar-data-clinica.py
# Esperar a que se completen todas las transformaciones
```

#### 4ï¸âƒ£ **Ejecutar Carga (Gold)**
```python
# Run: cargar-data-clinica.py
```

### OpciÃ³n 2: EjecuciÃ³n mediante Jobs en Databricks

1. Crear **Job** con tareas secuenciales
2. Agregar tareas en siguiente orden:
   - preparacion-ambiente.sql
   - 6 notebooks de extracciÃ³n
   - transformar-data-clinica.py
   - cargar-data-clinica.py
3. Configurar notificaciones de estado
4. Agendar ejecuciÃ³n segÃºn necesidad

---

## ğŸ”„ Workflow Automatizado (CI/CD)

Este proyecto cuenta con un workflow automatizado de despliegue continuo mediante **GitHub Actions** que despliega y ejecuta el pipeline ETL completo en Databricks.

### ğŸ“Š Workflow: `wf_carga_datos_clinica`

El workflow estÃ¡ configurado para ejecutarse automÃ¡ticamente al hacer push a la rama `main` y orquesta todas las tareas del ETL en secuencia.

#### ConfiguraciÃ³n del Workflow

| Propiedad | Valor |
|-----------|-------|
| **Nombre** | `wf_carga_datos_clinica` |
| **Formato** | MULTI_TASK |
| **Cluster** | `cluster_etl` (existente) |
| **Timeout** | 7200 segundos (2 horas) |
| **Max Concurrent Runs** | 1 |
| **Schedule** | `0 0 8 * * ?` (8:00 AM diario) - PAUSED |
| **UbicaciÃ³n Notebooks** | `/prod/etl/` |

#### Tareas del Workflow

El workflow ejecuta las siguientes tareas en secuencia:

**1. Eliminar-Ambiente**
   - **Notebook**: `eliminar-ambiente.sql`
   - **DescripciÃ³n**: Limpia el ambiente previo
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `nombre_container`: "unit-catalog-clinica"
     - `nombre_storage`: "adlsbrscceu2d01"
     - `catalogo`: "catalogo_clinica"

**2. Preparacion-Ambiente** â¬…ï¸ *Depende de: Eliminar-Ambiente*
   - **Notebook**: `preparacion-ambiente.sql`
   - **DescripciÃ³n**: Crea catÃ¡logo, esquemas y tablas
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `nombre_container`: "unit-catalog-clinica"
     - `nombre_storage`: "adlsbrscceu2d01"
     - `nombre_container_raw`: "raw"
     - `nombre_storage_raw`: "dtlkbrscceu2d01"

**3. ExtracciÃ³n de Datos (6 tareas en paralelo)** â¬…ï¸ *Depende de: Preparacion-Ambiente*

   **3.1. Extraer-data-cirugia**
   - **Notebook**: `extraer-data-cirugia.py`
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `raw_datalake`: "dtlkbrscceu2d01"
     - `raw_container`: "raw"
     - `raw_file`: "cirugia.csv"
     - `bronze_schema`: "bronze"
     - `bronze_table`: "cirugia"

   **3.2. Extraer-data-consultas-medicas**
   - **Notebook**: `extraer-data-consultas-medicas.py`
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `raw_datalake`: "dtlkbrscceu2d01"
     - `raw_container`: "raw"
     - `raw_file`: "consultas_medicas.csv"
     - `bronze_schema`: "bronze"
     - `bronze_table`: "consultas_medicas"

   **3.3. Extraer-data-medicamento**
   - **Notebook**: `extraer-data-medicamento.py`
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `raw_datalake`: "dtlkbrscceu2d01"
     - `raw_container`: "raw"
     - `raw_file`: "medicamento.csv"
     - `bronze_schema`: "bronze"
     - `bronze_table`: "medicamento"

   **3.4. Extraer-data-medico**
   - **Notebook**: `extraer-data-medico.py`
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `raw_datalake`: "dtlkbrscceu2d01"
     - `raw_container`: "raw"
     - `raw_file`: "medico.csv"
     - `bronze_schema`: "bronze"
     - `bronze_table`: "medico"

   **3.5. Extraer-data-paciente**
   - **Notebook**: `extraer-data-paciente.py`
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `raw_datalake`: "dtlkbrscceu2d01"
     - `raw_container`: "raw"
     - `raw_file`: "paciente.csv"
     - `bronze_schema`: "bronze"
     - `bronze_table`: "paciente"

   **3.6. Extraer-data-historial-pacientes**
   - **Notebook**: `extraer-data-historial-pacientes.py`
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `cosmos_account`: "codbbrscceu2d01"
     - `cosmos_scope`: "accessScopeforCosmosDB"
     - `cosmos_secret`: "cosmosdbKey"
     - `cosmos_database`: "clinica"
     - `cosmos_container`: "raw"
     - `bronze_schema`: "bronze"
     - `bronze_table`: "historial_pacientes"

**4. Transformar-datos-clinica** â¬…ï¸ *Depende de: Todas las 6 tareas de extracciÃ³n*
   - **Notebook**: `transformar-data-clinica.py`
   - **DescripciÃ³n**: Transforma datos Bronze â†’ Silver
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `bronze_schema`: "bronze"
     - `bronze_pacientes`: "paciente"
     - `bronze_medicos`: "medico"
     - `bronze_medicamentos`: "medicamento"
     - `bronze_cirugias`: "cirugia"
     - `bronze_consultas_medicas`: "consultas_medicas"
     - `bronze_historial_paciente`: "historial_pacientes"
     - `silver_schema`: "silver"
     - `silver_pacientes`: "paciente"
     - `silver_medicos`: "medico"
     - `silver_medicamentos`: "medicamento"
     - `silver_cirugias`: "cirugia"
     - `silver_consultas_medicas`: "consultas_medicas"
     - `silver_historial_pacientes_medicamentos`: "historial_pacientes_medicamentos"
     - `silver_historial_pacientes_cirugias`: "historial_pacientes_cirugias"

**5. Cargar-datos-clinica** â¬…ï¸ *Depende de: Transformar-datos-clinica*
   - **Notebook**: `cargar-data-clinica.py`
   - **DescripciÃ³n**: Carga datos Silver â†’ Gold
   - **Timeout**: 3600s | **Retries**: 2
   - **ParÃ¡metros**:
     - `catalogo`: "catalogo_clinica"
     - `silver_schema`: "silver"
     - `silver_hist_pac_med_table`: "historial_pacientes_medicamentos"
     - `silver_hist_pac_cir_table`: "historial_pacientes_cirugias"
     - `silver_paciente_table`: "paciente"
     - `silver_medico_table`: "medico"
     - `silver_consultas_medicas_table`: "consultas_medicas"
     - `silver_medicamento_table`: "medicamento"
     - `silver_cirugia_table`: "cirugia"
     - `gold_schema`: "gold"
     - `gold_pac_per_cli_table`: "paciente_perfil_clinico"
     - `gold_consulta_por_medico_table`: "consulta_por_medico"
     - `gold_ingreso_por_especialidad_table`: "ingresos_por_especialidad"
     - `gold_medicamentos_consumo_table`: "medicamentos_consumo"

#### EjecuciÃ³n del Workflow

![EjecuciÃ³n Workflow - wf_carga_datos_clinica](assets/ejecucion_wf_carga_datos_clinica.jpg)

#### CaracterÃ­sticas del Deployment

- âœ… **Despliegue automÃ¡tico** de notebooks al workspace de producciÃ³n
- âœ… **ValidaciÃ³n de configuraciÃ³n** antes de ejecutar
- âœ… **Monitoreo en tiempo real** del estado de ejecuciÃ³n
- âœ… **ReutilizaciÃ³n de cluster** existente para optimizar costos
- âœ… **Notificaciones por email** en caso de fallo
- âœ… **Tags de ambiente**: `environment:production`, `project:gestion-clinica`, `cluster_used:cluster_etl`

#### Estado y Monitoreo

El workflow puede ser monitoreado desde:
- **GitHub Actions**: Ver logs de despliegue
- **Databricks UI**: Ver ejecuciÃ³n del job y estado de tareas
- **API Databricks**: Consultar estado programÃ¡ticamente

## ğŸ“Š DescripciÃ³n de Tablas

### BRONZE

#### `bronze.paciente`
```
Columnas:
- identificacion (INT) - PK
- nombre (STRING)
- apellido (STRING)
- fecha_nacimiento (DATE)
- genero (STRING)
- email (STRING)
- telefono (STRING)
- ciudad (STRING)
- pais (STRING)
- tipo_sangre (STRING)
```

#### `bronze.medico`
```
Columnas:
- id_medico (STRING) - PK
- nombre (STRING)
- apellido (STRING)
- especialidad (STRING)
- numero_licencia (STRING)
- hospital (STRING)
- ciudad (STRING)
- telefono (STRING)
- email (STRING)
- estado (STRING)
```

#### `bronze.medicamento`
```
Columnas:
- codigo_medicamento (STRING) - PK
- nombre_medicamento (STRING)
- principio_activo (STRING)
- dosis (INT)
- unidad (STRING)
- especialidad (STRING)
- fabricante (STRING)
- precio_unitario (INT)
- estado (STRING)
```

#### `bronze.cirugia`
```
Columnas:
- codigo_cirugia (STRING) - PK
- nombre_cirugia (STRING)
- especialidad (STRING)
- duracion_promedio_minutos (INT)
- complejidad (STRING)
- costo_base (INT)
- riesgo_nivel (STRING)
- estado (STRING)
```

#### `bronze.consultas_medicas`
```
Columnas:
- codigo_consulta (STRING) - PK
- id_paciente (INT) - FK
- fecha_consulta (DATE)
- id_medico (STRING) - FK
- especialidad (STRING)
- motivo (STRING)
- diagnostico (STRING)
- costo_consulta (INT)
- estado (STRING)
```

---

## ğŸ”§ Notas TÃ©cnicas

### **LibrerÃ­as Utilizadas**

```python
# Spark SQL
from pyspark.sql.functions import (
    count, current_timestamp, coalesce, lit, col, sum, avg, 
    countDistinct, round, collect_set, max, greatest,
    explode_outer, trim, upper, lower
)

# Tipos de datos
from pyspark.sql.types import (
    StructType, StructField, StringType, IntegerType, DateType,
    ArrayType
)
```

### **Delta Lake Features**

- **ACID Transactions** para garantizar consistencia
- **Time Travel** para acceder versiones histÃ³ricas
- **Schema Enforcement** para validar estructura
- **Unified Batch & Streaming** (preparado para futuras mejoras)

### **Optimizaciones**

- Particionamiento por fecha en tablas grandes
- Z-Order clustering en campos frecuentes
- CompactaciÃ³n automÃ¡tica de archivos pequeÃ±os
- VacÃ­o de snapshots antiguos

### **Control de Calidad**

- Timestamps de carga en cada tabla
- Conteo de registros en cada proceso
- ValidaciÃ³n de valores NULL
- DetecciÃ³n de duplicados

---

## ğŸ”„ Flujo de ReversiÃ³n

En caso de necesidad, ejecutar scripts de limpieza:

### Eliminar Estructura Completa
```sql
Run: reversion/eliminar-medallion.sql
-- Elimina catÃ¡logo y todas las tablas
-- Regresa a estado inicial
```

---

**Ãšltima actualizaciÃ³n**: Febrero 2026  
**VersiÃ³n**: 1.0.0  
**Status**: ProducciÃ³n âœ…
